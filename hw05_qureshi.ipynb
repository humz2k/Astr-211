{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'> ASTR 21100/31200</font>\n",
    "\n",
    "## <font color='blue'> Homework Assignment 5</font>\n",
    "    \n",
    " \n",
    "## <font color='blue'> undergraduate students (50 points + 10 extra-credit)</font>\n",
    "   \n",
    "### <font color='blue'> Distributed: Friday, April 29</font>\n",
    "\n",
    "### <font color='blue'> Due: Friday, May 6, 10pm</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.cosmology import LambdaCDM\n",
    "import astropy.units as u\n",
    "import scipy.interpolate\n",
    "import scipy.optimize\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "# the following commands make plots look better\n",
    "def plot_pretty(dpi=150,fontsize=15):\n",
    "    plt.rcParams['figure.dpi']= dpi\n",
    "    plt.rc(\"savefig\", dpi=dpi)\n",
    "    plt.rc('font', size=fontsize)\n",
    "    plt.rc('xtick', direction='in')\n",
    "    plt.rc('ytick', direction='in')\n",
    "    plt.rc('xtick.major', pad=5)\n",
    "    plt.rc('xtick.minor', pad=5)\n",
    "    plt.rc('ytick.major', pad=5)\n",
    "    plt.rc('ytick.minor', pad=5)\n",
    "    plt.rc('lines', dotted_pattern = [2., 2.])\n",
    "    plt.rc('legend',fontsize=5)\n",
    "    plt.rcParams['figure.figsize'] = [5, 5]\n",
    "\n",
    "plot_pretty()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#zCMB, mB, emB are redshift of SNia, its apparent B-band magnitude, and emB is its error\n",
    "# x1 and ex1 are stretch parameter measured for each SN and its uncertainty\n",
    "# csn and ecsn are color parameter and its uncertainty\n",
    "zCMB, mB, emB, x1, ex1, csn, ecsn = np.loadtxt('https://astro.uchicago.edu/~andrey/classes/a211/data/jla_lcparams.txt',\n",
    "                                               usecols=(1, 4, 5, 6, 7, 8, 9), unpack=True)\n",
    "\n",
    "print(\"read sample of %d supernovae...\"%(np.size(zCMB)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'>Exercise 1 (5 points): Constructing approximation for $d_L$</font>\n",
    "\n",
    "Using the best approximation for $d_L$ that you identified in ex 1 of hw 4, construct a Python list of approximations for each of the 740 supernovae redshift. In other words, for each supernova in the sample above, construct approximation $\\tilde{d}_L(\\Omega_{\\rm m0},\\Omega_\\Lambda)$ within the range $\\Omega_{\\rm m0}\\in[0,1]$, $\\Omega_{\\Lambda}\\in[0,1]$. Construct approximation and add object that computes $\\tilde{d}_L(\\Omega_{\\rm m0},\\Omega_\\Lambda)$ for input values of $\\Omega_{\\rm m0}$ and $\\Omega_\\Lambda$. \n",
    "\n",
    "\n",
    "Namely, if the list is named <tt>dlz</tt>, you should be able to compute $d_L$ for a given supernova redshift $z_i$ and <tt>om</tt>, <tt>oml</tt> values as <tt>dlz[i](om, oml)</tt>. \n",
    "\n",
    "Test your list via direct calculations of $d_L$ using your own function or using AstroPy function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "def d_l_tilde_astropy(z, H0, Om0, OmL, clight=2.99792e5):\n",
    "    cosmo = LambdaCDM(H0=H0, Om0=Om0, Ode0=OmL)\n",
    "\n",
    "    return cosmo.luminosity_distance(z=z) / u.Mpc / (clight/H0)\n",
    "\n",
    "def get_dl_train_test(ntrain=15, z=1.0, H0=70., clight=2.99792e5,\n",
    "                      om0min=0., om0max = 1., omlmin=0., omlmax=1., spacing=np.linspace):\n",
    "\n",
    "    om0tr = spacing(om0min, om0max, ntrain)\n",
    "    omltr = spacing(omlmin, omlmax, ntrain)\n",
    "\n",
    "    dl_train = np.zeros((ntrain, ntrain))\n",
    "    for i, omd in enumerate(om0tr):\n",
    "        for j, omld in enumerate(omltr):\n",
    "                dl_train[i,j] = d_l_tilde_astropy(z, H0, omd, omld, clight = clight)\n",
    "\n",
    "    return om0tr, omltr, dl_train\n",
    "\n",
    "def train_model(ntrain=15, z=1.0, H0=70.,clight=2.99792e5,om0min=0., om0max = 1., omlmin=0., omlmax=1., s=0, kx=3, ky=3,spacing=np.linspace):\n",
    "    om0tr, omltr, dl_train = get_dl_train_test(ntrain=ntrain, z=z, H0=H0, clight=clight, om0min=om0min, om0max=om0max, omlmin=omlmin, omlmax=omlmax, spacing=spacing)\n",
    "    return scipy.interpolate.RectBivariateSpline(om0tr, omltr, dl_train, s=s, kx=kx, ky=ky)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "constants = {\n",
    "\"H0\": 70.,\n",
    "\"clight\": 2.99792e5\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Model Parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "parameters = {\n",
    "\"ntrain\": 5,\n",
    "\"om0min\": 0.,\n",
    "\"om0max\": 1.,\n",
    "\"omlmin\": 0.,\n",
    "\"omlmax\": 1.,\n",
    "\"s\": 0,\n",
    "\"kx\": 3,\n",
    "\"ky\": 3,\n",
    "\"spacing\": np.linspace\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "print(\"Training Models\")\n",
    "dlz = {}\n",
    "for idx,z in enumerate(zCMB):\n",
    "    if idx % (len(zCMB)//10) == 0:\n",
    "        if idx == 0:\n",
    "            print(\"   ->   0% done...\")\n",
    "        else:\n",
    "            print(\"   ->  \" + str(round((idx/len(zCMB))*100)) + \"% done...\")\n",
    "    dlz[z] = train_model(**parameters, **constants, z=z)\n",
    "print(\"   -> 100% done...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "n_samples = 100\n",
    "print(\"Testing the models using\",n_samples,\"random samples...\")\n",
    "sampled_frac_err = np.empty(n_samples,dtype=np.float64)\n",
    "for i in range(n_samples):\n",
    "    z = np.random.choice(zCMB)\n",
    "    model = dlz[z]\n",
    "    om0 = np.random.uniform()\n",
    "    omL = np.random.uniform()\n",
    "    model_val = model(om0,omL)\n",
    "    direct_val = d_l_tilde_astropy(z,constants[\"H0\"],om0,omL)\n",
    "    sampled_frac_err[i] = np.abs(model_val/direct_val -1.)\n",
    "\n",
    "print(\"Max Frac Err:\",np.max(sampled_frac_err))\n",
    "print(\"Min Frac Err:\",np.min(sampled_frac_err))\n",
    "print(\"Mean Frac Err:\",np.mean(sampled_frac_err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'>Exercise 2 (10 points): Implementing likelihood and finding parameter values that maximizes likelihood of supernovae type Ia data given model parameters</font>\n",
    "\n",
    "**Task 2a (5 points).** Implement a function to comput the likelihood using the expression:\n",
    "\n",
    "$$\\ln L(\\mathbf{y}\\vert\\mathbf{x}) = -\\frac{1}{2}\\,\\sum\\limits_{i=0}^{N_{\\rm SN}-1}\\frac{\\Delta\\mu^2}{\\sigma_{\\Delta\\mu,i}^2}-\\frac{1}{2}\\sum\\limits_{i=0}^{N_{\\rm SN}-1}\\ln(2\\pi\\sigma_{\\Delta\\mu,i}^2)$$\n",
    "\n",
    "and $\\sigma_{\\Delta\\mu,i}^2$ is total uncertainty of the observational estimate of the distance modulus that accounts for uncertainties in $m_B$, $x_1$, and $c$, which by rules of error propagation is: \n",
    "\n",
    "$$\\sigma_{\\Delta\\mu,i}^2 = \\sigma_{m_B}^2 + \\alpha^2\\sigma_{x1}^2 + \\beta^2\\sigma_c^2,$$\n",
    "\n",
    "which means that the error also depends on the two model parameters, $\\alpha$ and $\\beta$. \n",
    "\n",
    "The function should pass the supernova data and $d_L$ approximation via <tt>args</tt>. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "def loglikelihood(x, zCMB, mB, emB, x1, ex1, csn, ecsn, dlz, constants=constants):\n",
    "    om0, omL, M0, a, b = x\n",
    "    sig_mu_squared = emB**2 + (a**2) * (ex1**2) + (b**2) * (ecsn**2)\n",
    "    dl = np.array([dlz[z](om0,omL) for z in zCMB]).flatten()\n",
    "    mu = 5 * np.log10(dl) + 25\n",
    "    mu_obs = mB - (M0 + 5*np.log10(constants[\"clight\"]/constants[\"H0\"]) + 25)\n",
    "    del_mu_squared = (mu_obs - mu)**2\n",
    "    first = del_mu_squared/sig_mu_squared\n",
    "    second = np.log(2*np.pi*sig_mu_squared)\n",
    "    return -0.5*np.sum(first) - 0.5*np.sum(second)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2b. (5 points)** Test your function by implementing a helper function that computes $-\\ln L$ and find the values of 5 parameters $\\mathbf{x}=\\{\\Omega_{\\rm m0},\\Omega_\\Lambda, \\tilde{M}_0, \\alpha,\\beta\\}$ that minimize this function using the differential evolution function you implemented in hw 4, or <a href=\"https://docs.scipy.org/doc/scipy-0.15.1/reference/generated/scipy.optimize.differential_evolution.html\"><tt>scipy.minimize.differential_evolution</tt></a> function to find parameters that minimize $-\\ln L$ and print them out. \n",
    "\n",
    "To define bounds, you can use ranges for $\\Omega_{\\rm m0}$ and $\\Omega_\\Lambda$ of $[0,1]$ and for $\\tilde{M}_0$ say $[20, 28]$. For $\\alpha$ good choice for range is $[0.05, 0.3]$ and for $\\beta$: $[1., 5.]$. Feel free to experiment with these ranges. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Differential Evolution Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "func_kwargs = {\n",
    "\"zCMB\": zCMB,\n",
    "\"mB\": mB,\n",
    "\"emB\": emB,\n",
    "\"x1\": x1,\n",
    "\"ex1\": ex1,\n",
    "\"csn\": csn,\n",
    "\"ecsn\": ecsn,\n",
    "\"dlz\": dlz,\n",
    "\"constants\": constants\n",
    "}\n",
    "bounds = ((0,1),(0,1),(20,28),(0.05,0.3),(1,5))\n",
    "\n",
    "kwargs = {\n",
    "\"popsize\": 15,\n",
    "\"tol\": 0.01,\n",
    "\"atol\": 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "result = scipy.optimize.differential_evolution(loglikelihood,bounds,args=func_kwargs.values(),**kwargs)\n",
    "print(result)\n",
    "best_om0, best_omL, best_M0, best_a, best_b = result.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'>Exercise 3 (5 points): Using inverse transform </font>\n",
    "    \n",
    "to sample random numbers from the distribution $g(x)=A/\\sqrt{x}$ for $x\\in[1/a,a]$ where $a$ is a constant and $A$ is normalization constant.\n",
    "\n",
    "**Task 3a (1 point).** Derive expression for the normalization constant $A$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "\\int_{\\frac{1}{a}}^{a}g(x)\\,\\mathrm{d}x &= 1 \\\\\n",
    "\\int_{\\frac{1}{a}}^{a}\\frac{A}{\\sqrt{x}}\\,\\mathrm{d}x &= 1 \\\\\n",
    "A\\int_{\\frac{1}{a}}^{a}x^{-\\frac{1}{2}}\\,\\mathrm{d}x &= 1 \\\\\n",
    "A\\left[ 2x^{\\frac{1}{2}} \\right]_{\\frac{1}{a}}^a &= 1 \\\\\n",
    "A(2\\sqrt{a}-2\\sqrt{\\frac{1}{a}}) &= 1 \\\\\n",
    "A &= \\frac{1}{(2\\sqrt{a}-2\\sqrt{\\frac{1}{a}})} \\\\\n",
    "A &= \\frac{1}{2(\\sqrt{a}-\\sqrt{\\frac{1}{a}})} \\\\\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 3b (1 point).** Derive the expression for the cdf $P(x)$ and its inverse $x = P^{-1}(y)$, where $y$ is value in the range $[0,1]$. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "P(x) &= \\int_{\\frac{1}{a}}^{x}g(x')\\,\\mathrm{d}x'\\\\\n",
    "P(x) &= \\int_{\\frac{1}{a}}^{x}\\frac{A}{\\sqrt{x'}}\\,\\mathrm{d}x' \\\\\n",
    "P(x) &= \\int_{\\frac{1}{a}}^{x}\\frac{A}{\\sqrt{x'}}\\,\\mathrm{d}x' \\\\\n",
    "P(x) &= A(2\\sqrt{x}-2\\sqrt{\\frac{1}{a}}) \\\\\n",
    "P^{-1}(y) &= (\\frac{y}{2A}+\\sqrt{\\frac{1}{a}})^{2} \\\\\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 3c (3 points).** Assuming $a=2$ draw random numbers using inverse transform method using the inverse cdf you derive to draw $10^6$ sample tha follow pdf $g(x)$. Test your results by histogramming results and and comparing the histogram to the analytic expression for $g(x)$ shown as a line. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "def g(x,a=2):\n",
    "    A = 1/(2*(np.sqrt(a) - np.sqrt(1/a)))\n",
    "    return A/np.sqrt(x)\n",
    "\n",
    "def P(x,a=2):\n",
    "    A = 1/(2*(np.sqrt(a) - np.sqrt(1/a)))\n",
    "    return A*(2*np.sqrt(x) - 2*np.sqrt(1/a))\n",
    "\n",
    "def P_inverse(y,a=2):\n",
    "    A = 1/(2*(np.sqrt(a) - np.sqrt(1/a)))\n",
    "    return ((y/(2*A)) + np.sqrt((1/a)))**2\n",
    "\n",
    "a = 2\n",
    "xs = np.linspace(1/a,a,1000)\n",
    "nsamples = int(1e6)\n",
    "samples = P_inverse(np.random.uniform(size=nsamples),a)\n",
    "\n",
    "plt.plot(xs,g(xs,a),label=\"Analytic $g(x)$\",zorder=1,linewidth=2,alpha=0.9)\n",
    "plt.hist(samples,density=True,bins=100,label=\"Samples\",zorder=0)\n",
    "plt.xlabel(\"$x$\")\n",
    "plt.ylabel(\"$g(x)$\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'> Exercise 4: Implementing the affine-invariant MCMC algorithm of Goodman & Weare (2010) and using it to sample the likelihood (30 points + possible 10 extra-credit). </blue>\n",
    "    \n",
    "**Task 4a (20 points).**\n",
    "Implement the \"affine-invariant\" MCMC algorithm proposed by <a href=\"http://msp.org/camcos/2010/5-1/p04.xhtml\">Goodman & Weare (2010, hereafter GW10)</a> and described in <a href=\"https://drive.google.com/file/d/1h-0Be_HwXRdKOgdKSdtX0PiIe6-9Logg/view?usp=sharing\"><tt>10_multid_sampling_mcmc</tt></a> notebook in the form of a Python function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "def lngauss_nd(x, means, icov):\n",
    "    diff = x - means\n",
    "    return -0.5 * np.dot(diff.T, np.dot(icov, diff))\n",
    "\n",
    "def mcmc_gw10(x0, logpdf = None, args = None, nsteps = 10000):\n",
    "\n",
    "    xnow = np.copy(x0)\n",
    "    chain = []\n",
    "    indexes = np.repeat(np.reshape(np.arange(len(xnow)),(1,len(xnow))),len(xnow),axis=0)\n",
    "\n",
    "    mask = np.ones((len(xnow),len(xnow)),dtype=bool)\n",
    "    np.fill_diagonal(mask,False)\n",
    "\n",
    "    indexes = np.reshape(indexes.flatten()[mask.flatten()],(len(xnow),len(xnow)-1))\n",
    "\n",
    "    for step in range(nsteps):\n",
    "\n",
    "        indexes = indexes.T\n",
    "        np.random.shuffle(indexes)\n",
    "        indexes = indexes.T\n",
    "        nextindexes = np.append(np.diagonal(indexes),np.random.randint(0,len(xnow)-1))\n",
    "        xj = np.take(xnow,nextindexes,axis=0)\n",
    "\n",
    "        zr = np.reshape(P_inverse(np.random.uniform(size=len(xnow)),2),(1,len(xnow))).T\n",
    "\n",
    "        xprop = xj + (zr*(xnow-xj))\n",
    "\n",
    "        #this is the fastest way to do this (vectorizing logpdf is implemented as a for loop as well)\n",
    "        pi_xprop = np.exp(np.array([logpdf(j,*args) for j in xprop]))\n",
    "        #this is the fastest way to do this (vectorizing logpdf is implemented as a for loop as well)\n",
    "        pi_xnow = np.exp(np.array([logpdf(j,*args) for j in xnow]))\n",
    "\n",
    "        zrd = P_inverse(np.random.uniform(size=len(xnow)),2) ** (xnow.shape[1]-1)\n",
    "\n",
    "        pacc = np.clip(zrd*(pi_xprop/pi_xnow),0,1.0)\n",
    "\n",
    "        rand_tests = np.random.uniform(size=len(pacc))\n",
    "\n",
    "        accepted = rand_tests <= pacc\n",
    "\n",
    "        temp = np.copy(xnow)\n",
    "        xnow[accepted] = xprop[accepted]\n",
    "\n",
    "        chain.append(np.copy(xnow))\n",
    "    return np.stack(chain,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='darkblue'> Task 4b (3 points)</font>\n",
    "\n",
    "Test your implementation of the GW 10 MCMC algorithm by sampling $\\ln$ 2d Gaussian pdf using function <tt>lngauss_nd</tt> below. Plot resulting distributions of chain values for $\\Omega_{\\rm m0}$ and $\\Omega_\\Lambda$ along with the confidence contours that correspond to $1-$ and $2-\\sigma$ of the Gaussian distribution and enclose $0.6827$ and $0.9545$ of the total samples using example below using <tt>plot_2d_dist</tt> function from <tt>codes/plotting.py</tt>. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "means = np.array([0., 0.])\n",
    "s1, s2, r = 1.0, 1.0, 0.95\n",
    "\n",
    "cov = [[s1**2, r*s1*s2], [r*s1*s2, s2**2]]\n",
    "\n",
    "icov = np.linalg.inv(cov)\n",
    "args = [means, icov]\n",
    "\n",
    "ndim = 2\n",
    "nwalkers = 50\n",
    "nsteps = 10000\n",
    "p0 = np.zeros(((nwalkers, ndim)))\n",
    "for d in range(ndim):\n",
    "    p0[:,d] = 0.05*np.random.normal(size=nwalkers)\n",
    "\n",
    "chain = mcmc_gw10(p0, logpdf=lngauss_nd, args=args, nsteps=nsteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "def plot_2d_dist(x,y, xlim, ylim, nxbins, nybins, figsize=(5,5), xlabel='x', ylabel='y',\n",
    "                clevs=None):\n",
    "\n",
    "    def conf_interval(x, pdf, conf_level):\n",
    "        return np.sum(pdf[pdf > x])-conf_level\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.xlim(xlim[0], xlim[1])\n",
    "    plt.ylim(ylim[0], ylim[1])\n",
    "\n",
    "    if xlim[1] < 0.: ax.invert_xaxis()\n",
    "\n",
    "    H, xbins, ybins = np.histogram2d(x, y, bins=(np.linspace(xlim[0], xlim[1], nxbins),np.linspace(ylim[0], ylim[1], nybins)))\n",
    "\n",
    "    H = np.rot90(H); H = np.flipud(H);\n",
    "\n",
    "    X,Y = np.meshgrid(xbins[:-1],ybins[:-1])\n",
    "\n",
    "    H = H/np.sum(H)\n",
    "    Hmask = np.ma.masked_where(H==0,H)\n",
    "\n",
    "    pcol = ax.pcolormesh(X, Y,(Hmask),  cmap=plt.cm.BuPu, norm = LogNorm(), linewidth=0., rasterized=True, shading='auto')\n",
    "    pcol.set_edgecolor('face')\n",
    "\n",
    "    # plot contours if contour levels are specified in clevs\n",
    "    if clevs is not None:\n",
    "        lvls = []\n",
    "        for cld in clevs:\n",
    "            sig = scipy.optimize.brentq( conf_interval, 0., 1., args=(H,cld) )\n",
    "            lvls.append(sig)\n",
    "\n",
    "        ax.contour(X, Y, Hmask, linewidths=(1.0,0.75, 0.5, 0.25), colors='black', levels = sorted(lvls),\n",
    "                norm = LogNorm(), extent = [xbins[0], xbins[-1], ybins[0], ybins[-1]])\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "conflevs = [0.6827, 0.9545]\n",
    "\n",
    "x = chain[:,:,0].flatten()\n",
    "y = chain[:,:,1].flatten()\n",
    "\n",
    "plot_2d_dist(x, y, xlim=[-5, 5], ylim =[-5,5],\n",
    "             nxbins=100, nybins=100,\n",
    "             clevs=conflevs,\n",
    "             xlabel=r'${\\rm intercept}\\ c$',\n",
    "             ylabel=r'${\\rm slope}\\ b$', figsize=(5,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='darkblue'> Task 4c (7 points)</font>\n",
    "\n",
    "Write a function that defines natural logarithm of prior pdf for all parameters $\\ln p$. Write another function that defines unnormalized posterior pdf, i.e. combines $\\ln L$ (from ex 2 aove) and $\\ln p$ into $\\ln L(\\mathbf{y}\\vert\\mathbf{x}) + \\ln p(\\mathbf{x})=\\ln L(\\mathbf{y}\\vert\\mathbf{x})p(\\mathbf{x})$. For $p$ for all parameters you can assume uniform pdf defined between minimum and maximum value you choose for each parameter (these should be $0$ and $1$ for $\\Omega_{\\rm m0}$ and $\\Omega_\\Lambda$ not to extrapolate your approximation for $\\tilde{d}_L$. The total $\\ln$ of prior pdf for all parameters is a sun of $\\ln$ prior pdfs for individual parameters.\n",
    "\n",
    "* Use your implementation of GW10 or <tt>emcee</tt> package to sample $\\ln L(\\mathbf{y}\\vert\\mathbf{x})p(\\mathbf{x})$ using GW10 MCMC, initializing \"walker\" positions around the values of the best fit parameters you obtained in ex 2 above. \n",
    "\n",
    "* Plot resulting distributions of chain values for $\\Omega_{\\rm m0}$ and $\\Omega_\\Lambda$ along with the confidence contours that correspond to $1-$ and $2-\\sigma$ of the Gaussian distribution and enclose $0.6827$ and $0.9545$. \n",
    "\n",
    "* Use examples in [<tt>11_mcmc_stat_models</tt>](https://drive.google.com/file/d/1ksi7VjA48PutOS7TJ17FS5H2Ve0qmjv2/view?usp=sharing) notebook (for example, function <tt>chain_stats</tt> to output statistics about $\\Omega_{\\rm m0}$ and $\\Omega_\\Lambda$) to output statistics of these quantities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "x0 = result.x\n",
    "\n",
    "bounds = ((0,1),(0,1),(20,28),(0.05,0.3),(1,5))\n",
    "\n",
    "def prior(xd,bounds):\n",
    "    for bound,i in zip(bounds,xd):\n",
    "        print(bound,i)\n",
    "print(prior(x0,bounds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
